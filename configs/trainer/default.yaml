# @package _global_.trainer

max_epochs: 100  # Specific number of epochs
accelerator: cuda  # force to use GPU so I don't need to write in code
devices: 1  # Will be auto-detected in code
deterministic: false # True for all others but false for CBAM for CNN_transformer and SFNO 
num_sanity_val_steps: 0
precision: 32

# Define callbacks as a list for Hydra instantiation
callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint  # Save the best model
    monitor: "val/loss"
    save_top_k: 1
    mode: "min"
    save_last: true
    dirpath: "${hydra:runtime.output_dir}/checkpoints"   # Where to save the model
    filename: "epoch={epoch:02d}-step={step}"

    
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: "epoch"

